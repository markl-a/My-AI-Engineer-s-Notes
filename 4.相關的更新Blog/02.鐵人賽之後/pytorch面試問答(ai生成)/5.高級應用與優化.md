### 5. **高級應用與優化**
   - **如何在 PyTorch 中實現模型的遷移學習？**
   - **解釋如何使用 GPU 進行加速。如何在多個 GPU 上進行模型訓練？**
   - **如何優化模型的計算性能，例如使用 `torch.jit` 或模型壓縮技術？**
   - **你有使用過混合精度訓練 (Mixed Precision Training) 嗎？它有什麼優勢？**


### 1. **如何在 PyTorch 中實現自訂的自動微分功能？你會如何設計一個自訂的 Autograd 函數？**

**自訂自動微分的必要性：**
- PyTorch 的自動微分（Autograd）系統通常可以自動計算大多數操作的梯度。但是，在某些情況下，例如需要自訂操作或優化梯度計算性能時，可以通過定義自訂的 Autograd 函數來實現自動微分。

**如何實現自訂 Autograd 函數：**
- 可以使用 `torch.autograd.Function` 來定義自訂的前向和反向傳播邏輯。這需要實現 `forward` 和 `backward` 兩個靜態方法：
  - **`forward(ctx, *inputs)`**：定義前向計算邏輯，將輸入轉換為輸出。`ctx` 是上下文對象，可以用來存儲需要在反向傳播中使用的中間結果。
  - **`backward(ctx, *grad_outputs)`**：定義反向計算邏輯，計算輸出對輸入的梯度。`grad_outputs` 是來自上層的梯度。

**示例：自訂平方操作的 Autograd 函數**

```python
import torch

class CustomSquareFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input):
        # 將輸入的平方結果保存到上下文
        ctx.save_for_backward(input)
        return input * input

    @staticmethod
    def backward(ctx, grad_output):
        # 從上下文中檢索原始輸入
        input, = ctx.saved_tensors
        # 計算梯度（2 * input）
        grad_input = grad_output * 2 * input
        return grad_input

# 使用自訂的 Autograd 函數
input_tensor = torch.tensor([2.0, 3.0], requires_grad=True)
output_tensor = CustomSquareFunction.apply(input_tensor)
output_tensor.backward(torch.tensor([1.0, 1.0]))

print(input_tensor.grad)  # 輸出: tensor([4., 6.])
```

在這個例子中，我們定義了一個自訂的平方操作 `CustomSquareFunction`，並實現了它的前向和反向傳播邏輯。使用這個自訂操作時，`forward` 和 `backward` 函數會自動處理前向計算和梯度計算。

### 2. **你如何在 PyTorch 中使用混合精度訓練來加速模型訓練並減少內存使用？有哪些注意事項？**

**混合精度訓練的概念：**
- 混合精度訓練是指在訓練過程中同時使用 32 位浮點數（FP32）和 16 位浮點數（FP16）進行計算。這種方法可以提高計算效率，減少內存占用，並加速模型訓練，特別是在現代 GPU（如 NVIDIA 的 Volta、Ampere 架構）上，這些 GPU 支持高效的 FP16 計算。

**如何在 PyTorch 中實現混合精度訓練：**
1. **使用 AMP (Automatic Mixed Precision)**：PyTorch 提供了 `torch.cuda.amp` 工具來輔助實現混合精度訓練。AMP 自動處理精度切換和損失縮放，以防止數值不穩定問題。

2. **示例：使用 AMP 進行混合精度訓練**

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast

# 定義簡單的模型、優化器和損失函數
model = nn.Linear(10, 2).cuda()
optimizer = optim.SGD(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# 使用 GradScaler 來縮放梯度
scaler = GradScaler()

# 模擬數據加載
data = torch.randn(64, 10).cuda()
target = torch.randint(0, 2, (64,)).cuda()

# 訓練循環
for epoch in range(10):
    optimizer.zero_grad()
    
    # 使用 autocast 進行前向傳播
    with autocast():
        output = model(data)
        loss = criterion(output, target)
    
    # 使用 scaler 縮放損失並反向傳播
    scaler.scale(loss).backward()
    
    # 更新參數
    scaler.step(optimizer)
    scaler.update()
    
    print(f'Epoch {epoch+1}, Loss: {loss.item()}')
```

在這個例子中，我們使用 `autocast` 來自動選擇適合的精度進行計算，並使用 `GradScaler` 來縮放梯度，確保反向傳播時數值穩定。

**注意事項：**
1. **數值穩定性**：FP16 計算精度較低，可能導致數值不穩定。使用損失縮放（`GradScaler`）是防止梯度下溢的重要措施。
2. **兼容性**：並非所有操作都支持 FP16，需要通過 `autocast` 自動選擇合適的精度進行計算。
3. **性能測試**：在某些情況下，混合精度訓練可能不會顯著提高性能，尤其是在較小的模型或較少的訓練數據時。建議進行性能測試，以確定是否適合使用混合精度。

### 3. **什麼是 PyTorch 的分布式數據並行（Distributed Data Parallel, DDP）？如何在多 GPU 或多節點環境中配置和使用 DDP？**

**分布式數據並行（DDP）的概念：**
- DDP 是 PyTorch 中的一種分布式訓練方法，旨在在多個 GPU 或多個節點上高效地訓練大型模型。DDP 通過在每個 GPU 上運行一個模型副本，並在每個前向和反向傳播步驟之後進行梯度同步，以保持模型的一致性。

**DDP 的優勢：**
- **高效同步**：DDP 在每個 GPU 上獨立計算梯度，然後通過跨 GPU 同步梯度來進行參數更新。這種方式比傳統的數據並行方法（如 `DataParallel`）更高效，減少了瓶頸和開銷。
- **可擴展性**：DDP 可以在多個節點和多個 GPU 上進行擴展，適用於大型分布式訓練任務。

**如何配置和使用 DDP：**

1. **初始化分布式環境**：在訓練腳本的開頭初始化分布式環境。
2. **封裝模型**：使用 `torch.nn.parallel.DistributedDataParallel` 封裝模型。
3. **設置數據加載器**：確保每個進程使用不同的數據子集，可以使用 `torch.utils.data.distributed.DistributedSampler` 來分配數據。

**示例：使用 DDP 進行多 GPU 分布式訓練**

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, DistributedSampler
from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms

def train(rank, world_size):
    # 初始化分布式環境
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
    
    # 設置模型、數據集和數據加載器
    model = nn.Linear(10, 2).to(rank)
    ddp_model = DDP(model, device_ids=[rank])

    transform = transforms.Compose([transforms.ToTensor()])
    dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)
    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)
    dataloader = DataLoader(dataset, batch_size=64, sampler=sampler)

    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss().to(rank)
    
    for epoch in range(10):
        for data, target in dataloader:
            data, target = data.to(rank), target.to(rank)
            optimizer.zero_grad()
            output = ddp_model(data

)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
        print(f'Rank {rank}, Epoch {epoch+1}, Loss: {loss.item()}')

    # 清理分布式環境
    dist.destroy_process_group()

# 設置分布式訓練參數
world_size = 2
torch.multiprocessing.spawn(train, args=(world_size,), nprocs=world_size, join=True)
```

在這個例子中，我們使用了 DDP 在兩個 GPU 上進行分布式訓練。每個 GPU 運行一個訓練進程，並通過 NCCL 後端進行通信和同步。

**注意事項：**
1. **啟動方式**：需要使用 `torch.multiprocessing.spawn` 或其他多進程啟動方法來啟動多個訓練進程。
2. **環境設置**：確保每個節點都配置了正確的環境變量，例如 `MASTER_ADDR` 和 `MASTER_PORT`。
3. **同步開銷**：DDP 的性能依賴於有效的同步和通信，因此需要確保網絡帶寬和延遲足夠支援高效的分布式訓練。

### 4. **在 PyTorch 中，如何使用模型壓縮技術（如剪枝、量化）來優化模型？這些技術對性能有什麼影響？**

**模型壓縮技術的概念：**
- 模型壓縮技術旨在減少模型的計算負擔和內存佔用，提高推理速度，特別適用於資源受限的設備（如移動設備和嵌入式系統）。常見的壓縮技術包括剪枝和量化。

**剪枝（Pruning）：**
- 剪枝是通過去除不重要的權重或神經元來減少模型的大小。這些不重要的權重對模型的輸出影響較小，因此可以安全地移除。

**量化（Quantization）：**
- 量化是將模型的浮點數精度降低為低位整數（如從 FP32 到 INT8），以減少模型佔用的內存和計算量。量化後的模型在內存使用和計算效率方面有顯著改善。

**如何在 PyTorch 中實現模型壓縮：**
1. **動態量化（Dynamic Quantization）**：這種量化技術在推理過程中自動將張量轉換為低精度格式。
   ```python
   import torch
   import torchvision.models as models

   model = models.resnet18(pretrained=True)
   quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)
   ```
2. **靜態量化（Static Quantization）**：需要在量化前對模型進行校準。
   ```python
   import torch.quantization

   model.eval()
   model.qconfig = torch.quantization.get_default_qconfig('fbgemm')
   torch.quantization.prepare(model, inplace=True)
   # 進行校準
   for data, target in calibration_loader:
       model(data)
   torch.quantization.convert(model, inplace=True)
   ```

3. **模型剪枝**：使用 PyTorch 的 `torch.nn.utils.prune` 模塊來實現層剪枝。
   ```python
   import torch.nn.utils.prune as prune

   model = nn.Linear(10, 10)
   prune.random_unstructured(model, name="weight", amount=0.3)  # 隨機剪去 30% 的權重
   ```

**這些技術對性能的影響：**
1. **推理速度**：量化可以顯著提高模型的推理速度，特別是在支持低精度計算的硬件上。
2. **內存使用**：剪枝和量化都能有效減少模型佔用的內存，適合部署在資源受限的設備上。
3. **精度影響**：在大多數情況下，剪枝和量化可能會導致模型精度略微下降，因此需要在壓縮前後進行精度測試。

好的，我將繼續回答剩下的有關 PyTorch 高級應用與優化的問題，並詳細解釋每個問題的答案。

### 5. **如何在 PyTorch 中使用 JIT 編譯來優化模型的推理速度？JIT 有哪些優勢和限制？**

**JIT 編譯的概念：**
- PyTorch 的 JIT（Just-In-Time）編譯是一種優化技術，允許動態生成高效的機器碼以提高模型的推理速度。JIT 提供了兩種主要的方式：`torch.jit.trace` 和 `torch.jit.script`。這些工具可以將模型轉換為 TorchScript，然後在高效執行引擎中運行。

**如何在 PyTorch 中使用 JIT 編譯：**

1. **使用 `torch.jit.trace` 進行追蹤編譯：**
   - `trace` 方法適合對輸入形狀固定且不包含分支結構的模型進行編譯。它會根據輸入的範例數據追蹤模型的運行過程，生成對應的 TorchScript。

   ```python
   import torch
   import torch.nn as nn

   # 定義簡單的模型
   class SimpleModel(nn.Module):
       def __init__(self):
           super(SimpleModel, self).__init__()
           self.fc1 = nn.Linear(10, 5)

       def forward(self, x):
           return self.fc1(x)

   model = SimpleModel()
   example_input = torch.randn(1, 10)

   # 使用 JIT 進行追蹤
   traced_model = torch.jit.trace(model, example_input)
   traced_model.save("traced_model.pt")

   # 加載並使用
   loaded_model = torch.jit.load("traced_model.pt")
   output = loaded_model(example_input)
   print(output)
   ```

2. **使用 `torch.jit.script` 進行腳本化編譯：**
   - `script` 方法適合處理更複雜的控制流結構，如條件語句和循環。這種方法可以直接將 Python 函數轉換為 TorchScript。

   ```python
   import torch

   @torch.jit.script
   def scripted_function(x):
       if x.sum() > 0:
           return x * 2
       else:
           return x - 2

   x = torch.tensor([1.0, -1.0, 3.0])
   print(scripted_function(x))
   ```

**JIT 編譯的優勢：**
1. **提高推理速度**：通過將模型轉換為高效的機器碼，JIT 可以顯著提高推理速度，特別是在多次重複執行相同計算的場景中。
2. **優化跨平台部署**：TorchScript 模型可以在不依賴 Python 解釋器的環境中運行，如 C++ 應用程序中。
3. **靜態優化**：JIT 編譯器可以進行圖優化，如常量折疊、運算符融合，進一步提高性能。

**JIT 編譯的限制：**
1. **動態性限制**：JIT 對高度動態的 Python 特性支持有限，例如使用高級 Python 語法或運行時修改模型結構的場景。
2. **調試困難**：一旦模型被編譯成 TorchScript，調試信息可能變得較少，這使得診斷問題變得更困難。
3. **依賴範例輸入**：`torch.jit.trace` 僅能捕捉範例輸入時的執行路徑，對於存在動態分支的模型可能不適用。

### 6. **你如何在 PyTorch 中進行大規模數據集的高效數據處理？有什麼技術可以用來加速數據加載？**

**高效數據處理的挑戰：**
- 在訓練大型模型或處理大規模數據集時，數據加載和預處理通常是性能瓶頸。低效的數據加載會導致 GPU 資源閒置，從而降低整體訓練效率。

**技術和策略：**

1. **多進程數據加載**：使用 `DataLoader` 的 `num_workers` 參數來啟用多進程數據加載，每個進程會負責不同的數據批次的預處理和加載。
   ```python
   from torch.utils.data import DataLoader

   dataset = ...  # 定義數據集
   dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)  # 使用 4 個進程
   ```

2. **數據預取**：`DataLoader` 提供了預取功能，在當前批次被處理時，提前加載下一個批次的數據。
   ```python
   dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, prefetch_factor=2)
   ```

3. **使用內存映射文件（memory-mapped files）**：對於超大型數據集，可以使用內存映射文件來加速數據加載。這避免了將整個數據集加載到內存中的需求，只需在需要時讀取數據。
   ```python
   import numpy as np

   data = np.memmap('large_dataset.dat', dtype='float32', mode='r', shape=(1000000, 100))  # 設置內存映射
   ```

4. **增強數據增強管道**：使用如 `torchvision.transforms` 的高效增強方法來避免過多的數據複製操作。
   ```python
   from torchvision import transforms

   transform = transforms.Compose([
       transforms.Resize(256),
       transforms.RandomCrop(224),
       transforms.RandomHorizontalFlip(),
       transforms.ToTensor(),
   ])
   ```

5. **TFRecord 和 Petastorm**：這些數據格式和庫（如 Petastorm）可以用於高效讀取和處理分布式存儲的數據集。
   ```python
   import petastorm
   from petastorm import make_reader

   with make_reader('hdfs:///path/to/dataset') as reader:
       for batch in reader:
           process_batch(batch)
   ```

**這些技術的好處：**
- **減少 I/O 瓶頸**：多進程和數據預取可以最大化數據加載效率，使 GPU 能夠更連續地處理訓練任務。
- **提高吞吐量**：優化數據增強和處理流程，避免不必要的數據複製，可以顯著提高訓練吞吐量。
- **擴展性**：使用分布式數據存儲和處理技術，如 Petastorm，可以支持大規模的數據集和分布式訓練環境。

### 7. **在使用 Transformer 模型時，如何在 PyTorch 中實現自注意力機制（Self-Attention）？有什麼優化技巧可以提高計算效率？**

**自注意力機制的概念：**
- 自注意力（Self-Attention）是一種技術，用於在序列中建立每個位置與序列中其他位置的關聯。這種機制在 Transformer 模型中至關重要，它能夠同時考慮到遠距離的上下文信息。

**如何在 PyTorch 中實現自注意力：**

1. **基本自注意力實現：**
   - 自注意力機制包括三個主要步驟：計算 Query、Key 和 Value；計算注意力得分；加權求和得到輸出。

   ```python
   import torch
   import torch.nn.functional as F

   def self_attention(query, key, value):
       # 計算點積注意力得分
       scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(query.size(-1)))
       # 應用 softmax
       attention_weights = F.softmax(scores, dim=-1)
       # 加權求和
       output = torch.matmul(attention_weights, value)
       return output, attention_weights

   # 假設有一個序列 batch（batch_size, seq_length, embedding_dim）
   batch_size, seq_length, embedding_dim = 32, 10, 64
   query = key = value = torch.randn(batch_size, seq_length, embedding_dim)
   output, attn_weights = self_attention(query, key, value)
   ```

2. **使用 PyTorch 提供的 `nn.MultiheadAttention` 層**：
   - PyTorch 提供了高效的多頭注意力層，可以直接用於 Transformer 模型。

   ```python
   import torch.nn as nn

   multihead_attn = nn

.MultiheadAttention(embed_dim=embedding_dim, num_heads=8)
   query = key = value = torch.randn(seq_length, batch_size, embedding_dim)  # 需要將維度調整為 (seq_length, batch_size, embedding_dim)
   output, attn_weights = multihead_attn(query, key, value)
   ```

**優化技巧：**
1. **縮放點積注意力（Scaled Dot-Product Attention）**：通過除以根號下的鍵向量維度來標準化點積，以避免輸出過大。
   ```python
   scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(query.size(-1)))
   ```
2. **多頭注意力（Multi-Head Attention）**：通過使用多個注意力頭來捕獲更多的語義信息，每個頭專注於不同的部分信息。
3. **稀疏注意力**：在長序列上，稀疏注意力可以減少計算量，只關注局部區域或關鍵點，大幅度提升效率。
4. **訓練時使用分布式計算**：使用分布式數據並行（DDP）或模型並行（如 DeepSpeed）進行訓練，以提高大規模模型的訓練效率。
5. **高效實現**：使用 PyTorch 的 CUDA 擴展或 Fuse Operations（如 fused softmax 和 layer normalization），可以進一步提高計算效率。

### 8. **如何使用 PyTorch 進行圖神經網絡（Graph Neural Networks, GNNs）的建模？有哪些常見的 GNN 架構和應用？**

**圖神經網絡的概念：**
- 圖神經網絡（GNNs）是一類可以操作圖形結構數據的神經網絡模型。GNNs 能夠在圖形結構中進行節點、邊和全局級別的任務，如節點分類、鏈接預測和圖分類。

**如何使用 PyTorch 建模 GNN：**
1. **PyTorch Geometric**：這是基於 PyTorch 的圖神經網絡框架，提供了構建和訓練 GNN 的基本構建塊。
   ```python
   import torch
   import torch.nn.functional as F
   from torch_geometric.nn import GCNConv
   from torch_geometric.datasets import Planetoid

   # 加載數據集
   dataset = Planetoid(root='/tmp/Cora', name='Cora')

   # 定義 GNN 模型
   class GCN(torch.nn.Module):
       def __init__(self):
           super(GCN, self).__init__()
           self.conv1 = GCNConv(dataset.num_node_features, 16)
           self.conv2 = GCNConv(16, dataset.num_classes)

       def forward(self, data):
           x, edge_index = data.x, data.edge_index
           x = self.conv1(x, edge_index)
           x = F.relu(x)
           x = self.conv2(x, edge_index)
           return F.log_softmax(x, dim=1)

   model = GCN()
   data = dataset[0]

   # 訓練模型
   optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
   model.train()
   for epoch in range(200):
       optimizer.zero_grad()
       out = model(data)
       loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])
       loss.backward()
       optimizer.step()
   ```

2. **常見的 GNN 架構：**
   - **GCN（Graph Convolutional Network）**：圖卷積網絡，使用圖形卷積來聚合鄰居節點的信息。
   - **GAT（Graph Attention Network）**：圖注意力網絡，使用注意力機制來加權不同鄰居的影響。
   - **GraphSAGE**：使用樣本聚合的方式來擴展 GNN，適合大型圖。
   - **Graph Isomorphism Network (GIN)**：一種強大的結構辨識網絡，用於捕捉複雜的圖形結構。

**GNN 的應用：**
1. **社交網絡分析**：節點分類、社區檢測、鏈接預測等。
2. **分子圖分析**：預測分子的屬性和反應活性。
3. **推薦系統**：利用用戶行為圖來進行推薦。
4. **知識圖譜**：構建和查詢知識圖中的關係。
5. **異構網絡建模**：如在網絡安全中檢測異常流量。

### 9. **在 PyTorch 中，如何進行超參數調整？有什麼自動化的工具或方法可以用來優化超參數？**

**超參數調整的重要性：**
- 超參數調整是機器學習模型優化的關鍵步驟。選擇合適的超參數可以顯著提高模型的性能，如學習率、批次大小、神經元數量等。

**如何在 PyTorch 中進行超參數調整：**

1. **手動調整**：逐個改變超參數，觀察模型的性能變化。這種方法雖然簡單，但效率低且難以找到最佳組合。

2. **網格搜索（Grid Search）**：定義多個超參數的可能取值，遍歷所有可能的組合。這種方法適合於超參數範圍小的情況。
   ```python
   import itertools

   learning_rates = [0.001, 0.01, 0.1]
   batch_sizes = [32, 64, 128]
   all_combinations = list(itertools.product(learning_rates, batch_sizes))
   for lr, batch_size in all_combinations:
       # 訓練模型
       pass
   ```

3. **隨機搜索（Random Search）**：隨機選擇一些超參數組合進行測試，比網格搜索更高效，特別是在高維參數空間中。

4. **貝葉斯優化（Bayesian Optimization）**：這是一種基於概率模型的優化方法，可以根據以往的測試結果，智能地選擇下一組超參數進行測試。
   - 可以使用工具如 `hyperopt` 或 `Optuna` 來實現貝葉斯優化。

   ```python
   import optuna

   def objective(trial):
       lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)
       batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
       # 訓練模型，返回驗證集上的損失
       val_loss = train_and_evaluate_model(lr, batch_size)
       return val_loss

   study = optuna.create_study(direction='minimize')
   study.optimize(objective, n_trials=100)
   ```

5. **Ray Tune**：這是一個分布式超參數優化工具，可以與 PyTorch 無縫集成，適合大規模模型和分布式訓練。
   ```python
   from ray import tune

   def train(config):
       lr = config["lr"]
       # 訓練模型
       pass

   analysis = tune.run(
       train,
       config={
           "lr": tune.grid_search([0.001, 0.01, 0.1]),
       }
   )
   ```

**這些自動化工具和方法能幫助我們更高效地找到最佳超參數組合，從而提高模型性能。**

### 10. **你如何使用 PyTorch 的動態計算圖來實現複雜模型的靈活設計？這和靜態計算圖的框架有什麼區別？**

**動態計算圖的概念：**
- PyTorch 使用動態計算圖（Dynamic Computation Graph），也稱為定義即運行（Define-by-Run）。這意味著每次運行前向傳播時，都會動態構建計算圖。這使得開發和調試更加靈活和直觀，特別適合於包含條件語句和循環的複雜模型。

**如何利用動態計算圖設計靈活模型：**
1. **使用條件語句**：動態圖允許在前向傳播過程中使用 if-else 結構來實現不同的計算路徑。
   ```python
   class DynamicModel(nn.Module):
       def __init__(self, condition):
           super(DynamicModel, self).__init__()
           self.condition = condition
           self.fc1 = nn.Linear(10, 5)
           self.fc2 = nn.Linear(5, 2)

       def forward(self, x):
           if self.condition:
               x = F.relu(self.fc1(x))
           else:
               x = F.relu(self.fc2

(x))
           return x
   ```

2. **使用循環結構**：可以在前向傳播中包含循環，根據輸入的長度或內容動態調整計算過程。
   ```python
   class RNNModel(nn.Module):
       def __init__(self, input_size, hidden_size):
           super(RNNModel, self).__init__()
           self.hidden_size = hidden_size
           self.rnn_cell = nn.RNNCell(input_size, hidden_size)

       def forward(self, x):
           h_t = torch.zeros(x.size(0), self.hidden_size)
           for t in range(x.size(1)):  # 遍歷序列長度
               h_t = self.rnn_cell(x[:, t, :], h_t)
           return h_t
   ```

**與靜態計算圖（如 TensorFlow）的區別：**
1. **靈活性**：動態計算圖允許在每次前向傳播中改變計算圖結構，更適合於複雜、非線性的網絡設計。靜態計算圖在定義後不可改變，需要重新定義或編譯。
2. **易於調試**：動態計算圖可以使用標準的 Python 調試工具（如 print 和 pdb），這使得開發過程更加簡單直觀。靜態計算圖需要特定的工具（如 TensorFlow 的 tf.print）來調試。
3. **性能優化**：靜態計算圖可以在編譯時進行全局優化，可能在某些情況下比動態計算圖更快，但代價是缺少靈活性。

